import autogen, asyncio, time, json, logging
from backend.openai_helpers import call_llm
from backend.agents.expert_gc import run_expert_gc
from backend.json_utils import safe_load, BadJSON
from backend.chat_db import log_raw

logger = logging.getLogger(__name__)

PROMPT = """–¢—ã –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫. 
–í–µ—Ä–Ω–∏ —Ä–æ–≤–Ω–æ –û–î–ò–ù –æ–±—ä–µ–∫—Ç JSON –ë–ï–ó –∫–∞–∫–∏—Ö-–ª–∏–±–æ –ø–æ—è—Å–Ω–µ–Ω–∏–π:
{
 "need_clarify": true/false,
 "clarify": "...",
 "need_escalate": true/false,
 "draft": "..."
}
"""

def build_plan(user_q, slots, thread_id, turn):
    """–°—Ç—Ä–æ–∏—Ç –ø–ª–∞–Ω —Å –±–µ–∑–æ–ø–∞—Å–Ω—ã–º –ø–∞—Ä—Å–∏–Ω–≥–æ–º JSON"""
    txt, _ = call_llm("gpt-4o", f"{PROMPT}\n–í–æ–ø—Ä–æ—Å: {user_q}\n–°–ª–æ—Ç—ã:{slots}")
    
    # –õ–æ–≥–∏—Ä—É–µ–º —Å—ã—Ä–æ–π –æ—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏
    log_raw(thread_id, turn, "gpt-4o", txt)
    
    return safe_load(txt)

async def ask_planner(thread_id, user_q, slots):
    try:
        # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â–∏–π –Ω–æ–º–µ—Ä —Ö–æ–¥–∞ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        turn = int(time.time() * 1000) % 1000000  # –ü—Ä–æ—Å—Ç–æ–π —Å–ø–æ—Å–æ–± –ø–æ–ª—É—á–∏—Ç—å —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –Ω–æ–º–µ—Ä
        
        plan = build_plan(user_q, slots, thread_id, turn)
        
        # –ï—Å–ª–∏ –Ω—É–∂–Ω–∞ —É—Ç–æ—á–Ω—è—é—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        if plan.get("need_clarify"):
            return {"answer": plan.get("clarify"), "follow_up": True, "model": "gpt-4o"}
        # –ï—Å–ª–∏ —ç—Å–∫–∞–ª–∞—Ü–∏—è –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è
        if not plan.get("need_escalate"):
            return {"answer": plan.get("draft", ""), "model": "gpt-4o"}
        # –ò–Ω–∞—á–µ —ç—Å–∫–∞–ª–∏—Ä—É–µ–º –∫ —ç–∫—Å–ø–µ—Ä—Ç–Ω–æ–π —Ü–µ–ø–æ—á–∫–µ
        final = await run_expert_gc(thread_id, user_q, slots)
        return final
        
    except BadJSON as e:
        logger.warning("Planner JSON fail: %s", e)
        return {
            "type": "chat",
            "role": "system", 
            "content": "ü§ñ –ü–æ–∫–∞ –Ω–µ –ø–æ–Ω—è–ª —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫—É, —É—Ç–æ—á–Ω–∏—Ç–µ –ø–æ–∂–∞–ª—É–π—Å—Ç–∞."
        }
