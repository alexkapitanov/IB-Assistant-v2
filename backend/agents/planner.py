import autogen, asyncio, time, json, logging
from backend.openai_helpers import call_llm
from backend.agents.expert_gc import run_expert_gc
from backend.json_utils import safe_load, BadJSON
from backend.chat_db import log_raw          # –¥–ª—è –∞—É–¥–∏—Ç–∞

logger = logging.getLogger(__name__)

PROMPT = """–¢—ã –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫. –í–µ—Ä–Ω–∏ —Ä–æ–≤–Ω–æ –û–î–ò–ù –æ–±—ä–µ–∫—Ç JSON
–±–µ–∑ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è:
{
 "need_clarify": true/false,
 "clarify": "...",
 "need_escalate": true/false,
 "draft": "..."
}"""

def _call_planner_llm(thread_id: str, user_q: str, slots: dict):
    raw, _ = call_llm("gpt-4o", f"{PROMPT}\n–í–æ–ø—Ä–æ—Å: {user_q}\n–°–ª–æ—Ç—ã: {slots}")
    log_raw(thread_id, 0, "gpt-4.1", raw)       # turn_index=0 = —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π
    return safe_load(raw)

async def ask_planner(thread_id, user_q, slots):
    try:
        plan = _call_planner_llm(thread_id, user_q, slots)
    except BadJSON as e:
        logger.warning("Bad JSON from planner: %s", e)
        return {"type": "chat", "role": "system",
                "content": "ü§ñ –ù–µ —Å–º–æ–≥ —Ä–∞–∑–æ–±—Ä–∞—Ç—å –ø–ª–∞–Ω. –£—Ç–æ—á–Ω–∏—Ç–µ, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞."}
    
    # –ï—Å–ª–∏ –Ω—É–∂–Ω–∞ —É—Ç–æ—á–Ω—è—é—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
    if plan.get("need_clarify"):
        return {"answer": plan.get("clarify"), "follow_up": True, "model": "gpt-4o"}
    # –ï—Å–ª–∏ —ç—Å–∫–∞–ª–∞—Ü–∏—è –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è
    if not plan.get("need_escalate"):
        return {"answer": plan.get("draft", ""), "model": "gpt-4o"}
    # –ò–Ω–∞—á–µ —ç—Å–∫–∞–ª–∏—Ä—É–µ–º –∫ —ç–∫—Å–ø–µ—Ä—Ç–Ω–æ–π —Ü–µ–ø–æ—á–∫–µ
    final = await run_expert_gc(thread_id, user_q, slots)
    return final
